Adapters
Introduction
This developer guide provides specifications and instructions on how to develop an integration adapter for the NautilusTrader platform. Adapters provide connectivity to trading venues and data providers—translating raw venue APIs into Nautilus’s unified interface and normalized domain model.

Structure of an adapter
NautilusTrader adapters follow a layered architecture pattern with:

Rust core for networking clients and performance-critical operations.
Python layer (optional) for integrating into the legacy system.
Good references for consistent patterns are currently:

BitMEX
Bybit
OKX
Rust core (crates/adapters/your_adapter/)
The Rust layer handles:

HTTP client: Raw API communication, request signing, rate limiting.
WebSocket client: Low-latency streaming connections, message parsing.
Parsing: Fast conversion of venue data to Nautilus domain models.
Python bindings: PyO3 exports to make Rust functionality available to Python.
Typical Rust structure:

crates/adapters/your_adapter/
├── src/
│   ├── common/           # Shared types and utilities
│   │   ├── consts.rs     # Venue constants / broker IDs
│   │   ├── credential.rs # API key storage and signing helpers
│   │   ├── enums.rs      # Venue enums mirrored in REST/WS payloads
│   │   ├── urls.rs       # Environment & product aware base-url resolvers
│   │   ├── parse.rs      # Shared parsing helpers
│   │   └── testing.rs    # Fixtures reused across unit tests
│   ├── http/             # HTTP client implementation
│   │   ├── client.rs     # HTTP client with authentication
│   │   ├── models.rs     # Structs for REST payloads
│   │   ├── query.rs      # Request and query builders
│   │   └── parse.rs      # Response parsing functions
│   │   ├── messages.rs   # Structs for stream payloads
│   │   └── parse.rs      # Message parsing functions
│   ├── python/           # PyO3 Python bindings
│   ├── config.rs         # Configuration structures
│   └── lib.rs            # Library entry point
└── tests/                # Integration tests with mock servers

Python layer (nautilus_trader/adapters/your_adapter)
The Python layer provides the integration interface through these components:

Instrument Provider: Supplies instrument definitions via InstrumentProvider.
Data Client: Handles market data feeds and historical data requests via LiveDataClient and LiveMarketDataClient.
Execution Client: Manages order execution via LiveExecutionClient.
Factories: Converts venue-specific data to Nautilus domain models.
Configuration: User-facing configuration classes for client settings.
Typical Python structure:

nautilus_trader/adapters/your_adapter/
├── config.py     # Configuration classes
├── constants.py  # Adapter constants
├── data.py       # LiveDataClient/LiveMarketDataClient
├── execution.py  # LiveExecutionClient
├── factories.py  # Instrument factories
├── providers.py  # InstrumentProvider
└── __init__.py   # Package initialization

Adapter implementation steps
Create a new Python subpackage for your adapter.
Implement the Instrument Provider by inheriting from InstrumentProvider and implementing the necessary methods to load instruments.
Implement the Data Client by inheriting from either the LiveDataClient or LiveMarketDataClient class as applicable, providing implementations for the required methods.
Implement the Execution Client by inheriting from LiveExecutionClient and providing implementations for the required methods.
Create configuration classes to hold your adapter’s settings.
Test your adapter thoroughly to ensure all methods are correctly implemented and the adapter works as expected (see the Testing Guide).
Rust adapter patterns
Common code (common/): Group venue constants, credential helpers, enums, and reusable parsers under src/common. Adapters such as OKX keep submodules like consts, credential, enums, and urls alongside a testing module for fixtures, providing a single place for cross-cutting pieces. When an adapter has multiple environments or product categories, add a dedicated common::urls helper so REST/WebSocket base URLs stay in sync with the Python layer.
Configurations (config.rs): Expose typed config structs in src/config.rs so Python callers toggle venue-specific behaviour (see how OKX wires demo URLs, retries, and channel flags). Keep defaults minimal and delegate URL selection to helpers in common::urls.
Error taxonomy (error.rs): Centralise HTTP/WebSocket failure handling in an adapter-specific error enum. BitMEX, for example, separates retryable, non-retryable, and fatal variants while embedding the original transport error—follow that shape so operational tooling can react consistently.
Python exports (python/mod.rs): Mirror the Rust surface area through PyO3 modules by re-exporting clients, enums, and helper functions. When new functionality lands in Rust, add it to python/mod.rs so the Python layer stays in sync (the OKX adapter is a good reference).
Python bindings (python/): Expose Rust functionality to Python through PyO3. Mark venue-specific structs that need Python access with #[pyclass] and implement #[pymethods] blocks with #[getter] attributes for field access. For async methods in the HTTP client, use pyo3_async_runtimes::tokio::future_into_py to convert Rust futures into Python awaitables. When returning lists of custom types, map each item with Py::new(py, item) before constructing the Python list. Register all exported classes and enums in python/mod.rs using m.add_class::<YourType>() so they're available to Python code. Follow the pattern established in other adapters: prefixing Python-facing methods with py_* in Rust while using #[pyo3(name = "method_name")] to expose them without the prefix.
String interning: Use ustr::Ustr for any non-unique strings the platform stores repeatedly (venues, symbols, instrument IDs) to minimise allocations and comparisons.
Testing helpers (common/testing.rs): Store shared fixtures and payload loaders in src/common/testing.rs for use across HTTP and WebSocket unit tests. This keeps #[cfg(test)] helpers out of production modules and encourages reuse.
HTTP client patterns
Adapters use a two-layer HTTP client structure to enable efficient cloning for Python bindings while keeping the actual HTTP logic in a single place.

Client structure
Use an inner/outer client pattern with Arc wrapping:

use std::sync::Arc;
use nautilus_network::http::HttpClient;

// Inner client - contains actual HTTP logic
pub struct MyHttpInnerClient {
    base_url: String,
    client: HttpClient,  // Use nautilus_network::http::HttpClient, not reqwest directly
    credential: Option<Credential>,
    retry_manager: RetryManager<MyHttpError>,
    cancellation_token: CancellationToken,
}

// Outer client - wraps inner with Arc for cheap cloning (needed for Python)
pub struct MyHttpClient {
    pub(crate) inner: Arc<MyHttpInnerClient>,
}

Key points:

Inner client (*HttpInnerClient) contains all HTTP logic and state.
Outer client (*HttpClient) wraps the inner client in an Arc for efficient cloning.
Use nautilus_network::http::HttpClient instead of reqwest::Client directly - this provides rate limiting, retry logic, and consistent error handling.
The outer client delegates all methods to the inner client.
Parser functions
Parser functions convert venue-specific data structures into Nautilus domain objects. These belong in common/parse.rs for cross-cutting conversions (instruments, trades, bars) or http/parse.rs for REST-specific transformations. Each parser takes venue data plus context (account IDs, timestamps, instrument references) and returns a Nautilus domain type wrapped in Result.

Standard patterns:

Handle string-to-numeric conversions with proper error context using .parse::<f64>() and anyhow::Context.
Check for empty strings before parsing optional fields - venues often return "" instead of omitting fields.
Map venue enums to Nautilus enums explicitly with match statements rather than implementing automatic conversions that could hide mapping errors.
Accept instrument references when precision or other metadata is required for constructing Nautilus types (quantities, prices).
Use descriptive function names: parse_position_status_report, parse_order_status_report, parse_trade_tick.
Place parsing helpers (parse_price_with_precision, parse_timestamp) in the same module as private functions when they're reused across multiple parsers.

Method naming and organization
Organize HTTP methods into two distinct sections:

Low-level direct API calls.
High-level domain methods.
Naming conventions:

Low-level API methods: Prefix with http_ and place near the top of the impl block (e.g., http_get_instruments, http_place_order).
High-level domain methods: No prefix, placed in a separate section (e.g., submit_order, cancel_order).
Low-level methods take venue-specific types (builders, JSON values).
High-level methods take Nautilus domain objects (InstrumentId, ClientOrderId, OrderSide, etc.).
High-level method flow:

High-level domain methods in the inner client follow a three-step pattern: build venue-specific parameters from Nautilus types, call the corresponding http_* method, then parse or extract the response. For endpoints returning domain objects (positions, orders, trades), call parser functions from common/parse. For endpoints returning raw venue data (fee rates, balances), extract the result directly from the response envelope. Methods prefixed with request_* indicate they return domain data, while methods like submit_*, cancel_*, or modify_* perform actions and return acknowledgments.

The outer client delegates all methods directly to the inner client without additional logic - this separation exists solely to enable cheap cloning for Python bindings via Arc.

Query parameter builders
Use the derive_builder crate with proper defaults and ergonomic Option handling:

use derive_builder::Builder;

#[derive(Clone, Debug, Deserialize, Serialize, Builder)]
#[serde(rename_all = "camelCase")]
#[builder(setter(into, strip_option), default)]
pub struct InstrumentsInfoParams {
    pub category: ProductType,
    #[serde(skip_serializing_if = "Option::is_none")]
    pub symbol: Option<String>,
    #[serde(skip_serializing_if = "Option::is_none")]
    pub limit: Option<u32>,
}

impl Default for InstrumentsInfoParams {
    fn default() -> Self {
        Self {
            category: ProductType::Linear,
            symbol: None,
            limit: None,
        }
    }
}

Key attributes:

#[builder(setter(into, strip_option), default)] - enables clean API: .symbol("BTCUSDT") instead of .symbol(Some("BTCUSDT".to_string())).
#[serde(skip_serializing_if = "Option::is_none")] - omits optional fields from query strings.
Always implement Default for builder parameters.
Request signing and authentication
Keep signing logic in the inner client.

Error handling and retry logic
Use the RetryManager from nautilus_network for consistent retry behavior.

Rate limiting
Configure rate limiting through HttpClient.

WebSocket client patterns
WebSocket clients handle real-time streaming data and require careful management of connection state, authentication, subscriptions, and reconnection logic.

Client structure
WebSocket clients typically don't need the inner/outer pattern since they're not frequently cloned. Use a single struct with clear state management.

Authentication
Handle authentication separately from subscriptions.

Subscription management
Subscription lifecycle
A subscription represents any topic in one of two states:

State	Description
Pending	Subscription request sent to venue, awaiting acknowledgment
Confirmed	Venue acknowledged subscription and is actively streaming data
State transitions follow this lifecycle:

Trigger	Method Called	From State	To State	Notes
User subscribes	mark_subscribe()	—	Pending	Topic added to pending set
Venue confirms	confirm()	Pending	Confirmed	Moved from pending to confirmed
Venue rejects	mark_failure()	Pending	Pending	Stays pending for retry on reconnect
User unsubscribes	mark_unsubscribe()	Confirmed	Pending	Temporarily pending until ack
Unsubscribe ack	clear_pending()	Pending	Removed	Topic fully removed
Key principles:

subscription_count() reports only confirmed subscriptions, not pending ones.
Failed subscriptions remain pending and are automatically retried on reconnect.
Both confirmed and pending subscriptions are restored after reconnection.
Unsubscribe operations must check the op field in acknowledgments to avoid re-confirming topics.
Topic format patterns
Adapters use venue-specific delimiters to structure subscription topics:

Adapter	Delimiter	Example	Pattern
BitMEX	:	trade:XBTUSD	{channel}:{symbol}
OKX	:	trades:BTC-USDT-SWAP	{channel}:{symbol}
Bybit	.	orderbook.50.BTCUSDT	{channel}.{depth}.{symbol}
Parse topics using split_once() with the appropriate delimiter to extract channel and symbol components.

Reconnection logic
On reconnection, restore authentication and public subscriptions, but skip private channels that were explicitly unsubscribed.

Ping/Pong handling
Support both control frame pings and application-level pings.

Message routing
Route different message types to appropriate handlers.

Error handling
Classify errors to determine retry behavior:

#[derive(Debug, thiserror::Error)]
pub enum WebSocketError {
    #[error("Connection failed: {0}")]
    ConnectionFailed(String),

    #[error("Authentication failed: {0}")]
    AuthenticationFailed(String),

    #[error("Subscription failed: {0}")]
    SubscriptionFailed(String),

    #[error("Message parse error: {0}")]
    ParseError(String),
}

impl MyWebSocketClient {
    fn should_reconnect(&self, error: &WebSocketError) -> bool {
        matches!(
            error,
            WebSocketError::ConnectionFailed(_)
        )
    }
}

Modeling venue payloads
Use the following conventions when mirroring upstream schemas in Rust.

REST models (http::models and http::query)
Put request and response representations in src/http/models.rs and derive serde::Deserialize (add serde::Serialize when the adapter sends data back).
Mirror upstream payload names with blanket casing attributes such as #[serde(rename_all = "camelCase")] or #[serde(rename_all = "snake_case")]; only add per-field renames when the upstream key would be an invalid Rust identifier or collide with a keyword (for example #[serde(rename = "type")] pub order_type: String).
Keep helper structs for query parameters in src/http/query.rs, deriving serde::Serialize to remain type-safe and reusing constants from common::consts instead of duplicating literals.
WebSocket messages (websocket::messages)
Define streaming payload types in src/websocket/messages.rs, giving each venue topic a struct or enum that mirrors the upstream JSON.
Apply the same naming guidance as REST models: rely on blanket casing renames and keep field names aligned with the venue unless syntax forces a change; consider serde helpers such as #[serde(tag = "op")] or #[serde(flatten)] and document the choice.
Note any intentional deviations from the upstream schema in code comments and module docs so other contributors can follow the mapping quickly.
Testing
Adapters should ship two layers of coverage: the Rust crate that talks to the venue and the Python glue that exposes it to the wider platform. Keep the suites deterministic and colocated with the production code they protect.

Rust testing
Layout
crates/adapters/your_adapter/
├── src/
│   ├── http/
│   │   ├── client.rs      # HTTP client + unit tests
│   │   └── parse.rs       # REST payload parsers + unit tests
│   └── websocket/
│       ├── client.rs      # WebSocket client + unit tests
│       └── parse.rs       # Streaming parsers + unit tests
├── tests/
│   ├── http.rs            # Mock HTTP integration tests
│   └── websocket.rs       # Mock WebSocket integration tests
└── test_data/             # Canonical venue payloads used by the suites
    ├── http_get_{endpoint}.json  # Full venue responses with retCode/result/time
    └── ws_{message_type}.json    # WebSocket message samples

Place unit tests next to the module they exercise (#[cfg(test)] blocks). Use src/common/testing.rs (or an equivalent helper module) for shared fixtures so production files stay tidy.
Keep Axum-based integration suites under crates/adapters/<adapter>/tests/, mirroring the public APIs (HTTP client, WebSocket client, caches, reconnection flows).
Store upstream payload samples (snapshots, REST replies) under test_data/ and reference them from both unit and integration tests. Name test data files consistently: http_get_{endpoint_name}.json for REST responses, ws_{message_type}.json for WebSocket messages. Include complete venue response envelopes (status codes, timestamps, result wrappers) rather than just the data payload. Provide multiple realistic examples in each file - for instance, position data should include long, short, and flat positions to exercise all parser branches.
Unit tests
Focus on pure logic: parsers, signing helpers, canonicalisers, and any business rules that do not require a live transport.
Avoid duplicating coverage that the integration tests already provide.
Integration tests
Exercise the public API against Axum mock servers. At a minimum, mirror the BitMEX test surface (see crates/adapters/bitmex/tests/) so every adapter proves the same behaviours.

HTTP client integration coverage
Happy paths – fetch a representative public resource (e.g., instruments or mark price) and ensure the response is converted into Nautilus domain models.
Credential guard – call a private endpoint without credentials and assert a structured error; repeat with credentials to prove success.
Rate limiting / retry mapping – surface venue-specific rate-limit responses and assert the adapter produces the correct OkxError/BitmexHttpError variant so the retry policy can react.
Query builders – exercise builders for paginated/time-bounded endpoints (historical trades, candles) and assert the emitted query string matches the venue specification (after, before, limit, etc.).
Error translation – verify non-2xx upstream responses map to adapter error enums with the original code/message attached.
WebSocket client integration coverage
Login handshake – confirm a successful login flips the internal auth state and test failure cases where the server returns a non-zero code; the client should surface an error and avoid marking itself as authenticated.

Ping/Pong – prove both text-based and control-frame pings trigger immediate pong responses.

Subscription lifecycle – assert subscription requests/acks are emitted for public and private channels, and that unsubscribe calls remove entries from the cached subscription sets.

Reconnect behaviour – simulate a disconnect and ensure the client re-authenticates, restores public channels, and skips private channels that were explicitly unsubscribed pre-disconnect.

Message routing – feed representative data/ack/error payloads through the socket and assert they arrive on the public stream as the correct NautilusWsMessage variant.

Quota tagging – (optional but recommended) validate that order/cancel/amend operations are tagged with the appropriate quota label so rate limiting can be enforced independently of subscription traffic.

Prefer event-driven assertions with shared state (for example, collect subscription_events, track pending/confirmed topics, wait for connection_count transitions) instead of arbitrary sleep calls.

Use adapter-specific helpers to gate on explicit signals such as "auth confirmed" or "reconnection finished" so suites remain deterministic under load.

Python testing
Exercise the adapter’s Python surface (instrument providers, data/execution clients, factories) inside tests/integration_tests/adapters/<adapter>/.
Mock the PyO3 boundary (nautilus_pyo3 shims, stubbed Rust clients) so tests stay fast while verifying that configuration, factory wiring, and error handling match the exported Rust API.
Mirror the Rust integration coverage: when the Rust suite adds a new behaviour (e.g., reconnection replay, error propagation), assert the Python layer performs the same sequence (connect/disconnect, submit/amend/cancel translations, venue ID hand-off, failure handling). BitMEX’s Python tests provide the target level of detail.
Python adapter layer
Below is a step-by-step guide to building an adapter for a new data provider using the provided template.

InstrumentProvider
The InstrumentProvider supplies instrument definitions available on the venue. This includes loading all available instruments, specific instruments by ID, and applying filters to the instrument list.

from nautilus_trader.common.providers import InstrumentProvider
from nautilus_trader.model import InstrumentId


class TemplateInstrumentProvider(InstrumentProvider):
    """Example `InstrumentProvider` showing the minimal overrides required for a complete integration."""

    async def load_all_async(self, filters: dict | None = None) -> None:
        raise NotImplementedError("implement `load_all_async` in your adapter subclass")

    async def load_ids_async(self, instrument_ids: list[InstrumentId], filters: dict | None = None) -> None:
        raise NotImplementedError("implement `load_ids_async` in your adapter subclass")

    async def load_async(self, instrument_id: InstrumentId, filters: dict | None = None) -> None:
        raise NotImplementedError("implement `load_async` in your adapter subclass")


Key methods:

load_all_async: Loads all instruments asynchronously, optionally applying filters.
load_ids_async: Loads specific instruments by their IDs.
load_async: Loads a single instrument by its ID.
DataClient
The LiveDataClient handles the subscription and management of data feeds that are not specifically related to market data. This might include news feeds, custom data streams, or other data sources that enhance trading strategies but do not directly represent market activity.

from nautilus_trader.data.messages import RequestData
from nautilus_trader.data.messages import SubscribeData
from nautilus_trader.data.messages import UnsubscribeData
from nautilus_trader.live.data_client import LiveDataClient
from nautilus_trader.model import DataType


class TemplateLiveDataClient(LiveDataClient):
    """Example `LiveDataClient` showing the overridable abstract methods."""

    async def _connect(self) -> None:
        raise NotImplementedError("implement `_connect` in your adapter subclass")

    async def _disconnect(self) -> None:
        raise NotImplementedError("implement `_disconnect` in your adapter subclass")

    async def _subscribe(self, command: SubscribeData) -> None:
        raise NotImplementedError("implement `_subscribe` in your adapter subclass")

    async def _unsubscribe(self, command: UnsubscribeData) -> None:
        raise NotImplementedError("implement `_unsubscribe` in your adapter subclass")

    async def _request(self, request: RequestData) -> None:
        raise NotImplementedError("implement `_request` in your adapter subclass")

Key methods:

_connect: Establishes a connection to the data provider.
_disconnect: Closes the connection to the data provider.
_subscribe: Subscribes to a specific data type.
_unsubscribe: Unsubscribes from a specific data type.
_request: Requests data from the provider.
MarketDataClient
The MarketDataClient handles market-specific data such as order books, top-of-book quotes and trades, and instrument status updates. It focuses on providing historical and real-time market data that is essential for trading operations.

from nautilus_trader.data.messages import RequestBars
from nautilus_trader.data.messages import RequestData
from nautilus_trader.data.messages import RequestInstrument
from nautilus_trader.data.messages import RequestInstruments
from nautilus_trader.data.messages import RequestOrderBookSnapshot
from nautilus_trader.data.messages import RequestQuoteTicks
from nautilus_trader.data.messages import RequestTradeTicks
from nautilus_trader.data.messages import SubscribeBars
from nautilus_trader.data.messages import SubscribeData
from nautilus_trader.data.messages import SubscribeFundingRates
from nautilus_trader.data.messages import SubscribeIndexPrices
from nautilus_trader.data.messages import SubscribeInstrument
from nautilus_trader.data.messages import SubscribeInstrumentClose
from nautilus_trader.data.messages import SubscribeInstruments
from nautilus_trader.data.messages import SubscribeInstrumentStatus
from nautilus_trader.data.messages import SubscribeMarkPrices
from nautilus_trader.data.messages import SubscribeOrderBook
from nautilus_trader.data.messages import SubscribeQuoteTicks
from nautilus_trader.data.messages import SubscribeTradeTicks
from nautilus_trader.data.messages import UnsubscribeBars
from nautilus_trader.data.messages import UnsubscribeData
from nautilus_trader.data.messages import UnsubscribeFundingRates
from nautilus_trader.data.messages import UnsubscribeIndexPrices
from nautilus_trader.data.messages import UnsubscribeInstrument
from nautilus_trader.data.messages import UnsubscribeInstrumentClose
from nautilus_trader.data.messages import UnsubscribeInstruments
from nautilus_trader.data.messages import UnsubscribeInstrumentStatus
from nautilus_trader.data.messages import UnsubscribeMarkPrices
from nautilus_trader.data.messages import UnsubscribeOrderBook
from nautilus_trader.data.messages import UnsubscribeQuoteTicks
from nautilus_trader.data.messages import UnsubscribeTradeTicks
from nautilus_trader.live.data_client import LiveMarketDataClient


class TemplateLiveMarketDataClient(LiveMarketDataClient):
    """Example `LiveMarketDataClient` showing the overridable abstract methods."""

    async def _connect(self) -> None:
        raise NotImplementedError("implement `_connect` in your adapter subclass")

    async def _disconnect(self) -> None:
        raise NotImplementedError("implement `_disconnect` in your adapter subclass")

    async def _subscribe(self, command: SubscribeData) -> None:
        raise NotImplementedError("implement `_subscribe` in your adapter subclass")

    async def _unsubscribe(self, command: UnsubscribeData) -> None:
        raise NotImplementedError("implement `_unsubscribe` in your adapter subclass")

    async def _request(self, request: RequestData) -> None:
        raise NotImplementedError("implement `_request` in your adapter subclass")

    async def _subscribe_instruments(self, command: SubscribeInstruments) -> None:
        raise NotImplementedError("implement `_subscribe_instruments` in your adapter subclass")

    async def _unsubscribe_instruments(self, command: UnsubscribeInstruments) -> None:
        raise NotImplementedError("implement `_unsubscribe_instruments` in your adapter subclass")

    async def _subscribe_instrument(self, command: SubscribeInstrument) -> None:
        raise NotImplementedError("implement `_subscribe_instrument` in your adapter subclass")

    async def _unsubscribe_instrument(self, command: UnsubscribeInstrument) -> None:
        raise NotImplementedError("implement `_unsubscribe_instrument` in your adapter subclass")

    async def _subscribe_order_book_deltas(self, command: SubscribeOrderBook) -> None:
        raise NotImplementedError("implement `_subscribe_order_book_deltas` in your adapter subclass")

    async def _unsubscribe_order_book_deltas(self, command: UnsubscribeOrderBook) -> None:
        raise NotImplementedError("implement `_unsubscribe_order_book_deltas` in your adapter subclass")

    async def _subscribe_order_book_snapshots(self, command: SubscribeOrderBook) -> None:
        raise NotImplementedError("implement `_subscribe_order_book_snapshots` in your adapter subclass")

    async def _unsubscribe_order_book_snapshots(self, command: UnsubscribeOrderBook) -> None:
        raise NotImplementedError("implement `_unsubscribe_order_book_snapshots` in your adapter subclass")

    async def _subscribe_quote_ticks(self, command: SubscribeQuoteTicks) -> None:
        raise NotImplementedError("implement `_subscribe_quote_ticks` in your adapter subclass")

    async def _unsubscribe_quote_ticks(self, command: UnsubscribeQuoteTicks) -> None:
        raise NotImplementedError("implement `_unsubscribe_quote_ticks` in your adapter subclass")

    async def _subscribe_trade_ticks(self, command: SubscribeTradeTicks) -> None:
        raise NotImplementedError("implement `_subscribe_trade_ticks` in your adapter subclass")

    async def _unsubscribe_trade_ticks(self, command: UnsubscribeTradeTicks) -> None:
        raise NotImplementedError("implement `_unsubscribe_trade_ticks` in your adapter subclass")

    async def _subscribe_mark_prices(self, command: SubscribeMarkPrices) -> None:
        raise NotImplementedError("implement `_subscribe_mark_prices` in your adapter subclass")

    async def _unsubscribe_mark_prices(self, command: UnsubscribeMarkPrices) -> None:
        raise NotImplementedError("implement `_unsubscribe_mark_prices` in your adapter subclass")

    async def _subscribe_index_prices(self, command: SubscribeIndexPrices) -> None:
        raise NotImplementedError("implement `_subscribe_index_prices` in your adapter subclass")

    async def _unsubscribe_index_prices(self, command: UnsubscribeIndexPrices) -> None:
        raise NotImplementedError("implement `_unsubscribe_index_prices` in your adapter subclass")

    async def _subscribe_funding_rates(self, command: SubscribeFundingRates) -> None:
        raise NotImplementedError("implement `_subscribe_funding_rates` in your adapter subclass")

    async def _unsubscribe_funding_rates(self, command: UnsubscribeFundingRates) -> None:
        raise NotImplementedError("implement `_unsubscribe_funding_rates` in your adapter subclass")

    async def _subscribe_bars(self, command: SubscribeBars) -> None:
        raise NotImplementedError("implement `_subscribe_bars` in your adapter subclass")

    async def _unsubscribe_bars(self, command: UnsubscribeBars) -> None:
        raise NotImplementedError("implement `_unsubscribe_bars` in your adapter subclass")

    async def _subscribe_instrument_status(self, command: SubscribeInstrumentStatus) -> None:
        raise NotImplementedError("implement `_subscribe_instrument_status` in your adapter subclass")

    async def _unsubscribe_instrument_status(self, command: UnsubscribeInstrumentStatus) -> None:
        raise NotImplementedError("implement `_unsubscribe_instrument_status` in your adapter subclass")

    async def _subscribe_instrument_close(self, command: SubscribeInstrumentClose) -> None:
        raise NotImplementedError("implement `_subscribe_instrument_close` in your adapter subclass")

    async def _unsubscribe_instrument_close(self, command: UnsubscribeInstrumentClose) -> None:
        raise NotImplementedError("implement `_unsubscribe_instrument_close` in your adapter subclass")

    async def _request_instrument(self, request: RequestInstrument) -> None:
        raise NotImplementedError("implement `_request_instrument` in your adapter subclass")

    async def _request_instruments(self, request: RequestInstruments) -> None:
        raise NotImplementedError("implement `_request_instruments` in your adapter subclass")

    async def _request_quote_ticks(self, request: RequestQuoteTicks) -> None:
        raise NotImplementedError("implement `_request_quote_ticks` in your adapter subclass")

    async def _request_trade_ticks(self, request: RequestTradeTicks) -> None:
        raise NotImplementedError("implement `_request_trade_ticks` in your adapter subclass")

    async def _request_bars(self, request: RequestBars) -> None:
        raise NotImplementedError("implement `_request_bars` in your adapter subclass")

    async def _request_order_book_snapshot(self, request: RequestOrderBookSnapshot) -> None:
        raise NotImplementedError("implement `_request_order_book_snapshot` in your adapter subclass")

Key methods:

_connect: Establishes a connection to the venue APIs.
_disconnect: Closes the connection to the venue APIs.
_subscribe: Subscribes to generic data (base method for custom data types).
_unsubscribe: Unsubscribes from generic data (base method for custom data types).
_request: Requests generic data (base method for custom data types).
_subscribe_instruments: Subscribes to market data for multiple instruments.
_unsubscribe_instruments: Unsubscribes from market data for multiple instruments.
_subscribe_instrument: Subscribes to market data for a single instrument.
_unsubscribe_instrument: Unsubscribes from market data for a single instrument.
_subscribe_order_book_deltas: Subscribes to order book delta updates.
_unsubscribe_order_book_deltas: Unsubscribes from order book delta updates.
_subscribe_order_book_snapshots: Subscribes to order book snapshot updates.
_unsubscribe_order_book_snapshots: Unsubscribes from order book snapshot updates.
_subscribe_quote_ticks: Subscribes to top-of-book quote updates.
_unsubscribe_quote_ticks: Unsubscribes from quote tick updates.
_subscribe_trade_ticks: Subscribes to trade tick updates.
_unsubscribe_trade_ticks: Unsubscribes from trade tick updates.
_subscribe_mark_prices: Subscribes to mark price updates.
_unsubscribe_mark_prices: Unsubscribes from mark price updates.
_subscribe_index_prices: Subscribes to index price updates.
_unsubscribe_index_prices: Unsubscribes from index price updates.
_subscribe_funding_rates: Subscribes to funding rate updates.
_unsubscribe_funding_rates: Unsubscribes from funding rate updates.
_subscribe_bars: Subscribes to bar/candlestick updates.
_unsubscribe_bars: Unsubscribes from bar updates.
_subscribe_instrument_status: Subscribes to instrument status updates.
_unsubscribe_instrument_status: Unsubscribes from instrument status updates.
_subscribe_instrument_close: Subscribes to instrument close price updates.
_unsubscribe_instrument_close: Unsubscribes from instrument close price updates.
_request_instrument: Requests historical data for a single instrument.
_request_instruments: Requests historical data for multiple instruments.
_request_quote_ticks: Requests historical quote tick data.
_request_trade_ticks: Requests historical trade tick data.
_request_bars: Requests historical bar data.
_request_order_book_snapshot: Requests an order book snapshot.
ExecutionClient
The ExecutionClient is responsible for order management, including submission, modification, and cancellation of orders. It is a crucial component of the adapter that interacts with the venue trading system to manage and execute trades.

from nautilus_trader.execution.messages import BatchCancelOrders
from nautilus_trader.execution.messages import CancelAllOrders
from nautilus_trader.execution.messages import CancelOrder
from nautilus_trader.execution.messages import GenerateFillReports
from nautilus_trader.execution.messages import GenerateOrderStatusReport
from nautilus_trader.execution.messages import GenerateOrderStatusReports
from nautilus_trader.execution.messages import GeneratePositionStatusReports
from nautilus_trader.execution.messages import ModifyOrder
from nautilus_trader.execution.messages import SubmitOrder
from nautilus_trader.execution.messages import SubmitOrderList
from nautilus_trader.execution.reports import FillReport
from nautilus_trader.execution.reports import OrderStatusReport
from nautilus_trader.execution.reports import PositionStatusReport
from nautilus_trader.live.execution_client import LiveExecutionClient


class TemplateLiveExecutionClient(LiveExecutionClient):
    """Example `LiveExecutionClient` outlining the required overrides."""

    async def _connect(self) -> None:
        raise NotImplementedError("implement `_connect` in your adapter subclass")

    async def _disconnect(self) -> None:
        raise NotImplementedError("implement `_disconnect` in your adapter subclass")

    async def _submit_order(self, command: SubmitOrder) -> None:
        raise NotImplementedError("implement `_submit_order` in your adapter subclass")

    async def _submit_order_list(self, command: SubmitOrderList) -> None:
        raise NotImplementedError("implement `_submit_order_list` in your adapter subclass")

    async def _modify_order(self, command: ModifyOrder) -> None:
        raise NotImplementedError("implement `_modify_order` in your adapter subclass")

    async def _cancel_order(self, command: CancelOrder) -> None:
        raise NotImplementedError("implement `_cancel_order` in your adapter subclass")

    async def _cancel_all_orders(self, command: CancelAllOrders) -> None:
        raise NotImplementedError("implement `_cancel_all_orders` in your adapter subclass")

    async def _batch_cancel_orders(self, command: BatchCancelOrders) -> None:
        raise NotImplementedError("implement `_batch_cancel_orders` in your adapter subclass")

    async def generate_order_status_report(
        self,
        command: GenerateOrderStatusReport,
    ) -> OrderStatusReport | None:
        raise NotImplementedError("method `generate_order_status_report` must be implemented in the subclass")

    async def generate_order_status_reports(
        self,
        command: GenerateOrderStatusReports,
    ) -> list[OrderStatusReport]:
        raise NotImplementedError("method `generate_order_status_reports` must be implemented in the subclass")

    async def generate_fill_reports(
        self,
        command: GenerateFillReports,
    ) -> list[FillReport]:
        raise NotImplementedError("method `generate_fill_reports` must be implemented in the subclass")

    async def generate_position_status_reports(
        self,
        command: GeneratePositionStatusReports,
    ) -> list[PositionStatusReport]:
        raise NotImplementedError("method `generate_position_status_reports` must be implemented in the subclass")


Key methods:

_connect: Establishes a connection to the venue APIs.
_disconnect: Closes the connection to the venue APIs.
_submit_order: Submits a new order to the venue.
_submit_order_list: Submits a list of orders to the venue.
_modify_order: Modifies an existing order on the venue.
_cancel_order: Cancels a specific order on the venue.
_cancel_all_orders: Cancels all orders for an instrument on the venue.
_batch_cancel_orders: Cancels a batch of orders for an instrument on the venue.
generate_order_status_report: Generates a report for a specific order on the venue.
generate_order_status_reports: Generates reports for all orders on the venue.
generate_fill_reports: Generates reports for filled orders on the venue.
generate_position_status_reports: Generates reports for position status on the venue.
Configuration
The configuration file defines settings specific to the adapter, such as API keys and connection details. These settings are essential for initializing and managing the adapter’s connection to the data provider.

from nautilus_trader.config import LiveDataClientConfig
from nautilus_trader.config import LiveExecClientConfig


class TemplateDataClientConfig(LiveDataClientConfig):
    """Configuration for `TemplateDataClient` instances."""

    api_key: str
    api_secret: str
    base_url: str


class TemplateExecClientConfig(LiveExecClientConfig):
    """Configuration for `TemplateExecClient` instances."""

    api_key: str
    api_secret: str
    base_url: str

Key attributes:

api_key: The API key for authenticating with the data provider.
api_secret: The API secret for authenticating with the data provider.
base_url: The base URL for connecting to the data provider's API.
Common test scenarios
Exercise adapters across every venue behaviour they claim to support. Incorporate these scenarios into the Rust and Python suites.

Product coverage
Ensure each supported product family is tested.

Spot instruments
Derivatives (perpetuals, futures, swaps)
Options and structured products
Order flow
Cover each supported order type (limit, market, stop, conditional, etc.) under every venue time-in-force option, expiries, and rejection handling.
Submit buy and sell market orders and assert balance, position, and average-price updates align with venue responses.
Submit representative buy and sell limit orders, verifying acknowledgements, execution reports, full and partial fills, and cancel flows.
State management
Start sessions with existing open orders to ensure the adapter reconciles state on connect before issuing new commands.
Seed preloaded positions and confirm position snapshots, valuation, and PnL agree with the venue prior to trading.
Rust Style Guide
The Rust programming language is an ideal fit for implementing the mission-critical core of the platform and systems. Its strong type system, ownership model, and compile-time checks eliminate memory errors and data races by construction, while zero-cost abstractions and the absence of a garbage collector deliver C-like performance—critical for high-frequency trading workloads.

Cargo manifest conventions
In [dependencies], list internal crates (nautilus-*) first in alphabetical order, insert a blank line, then external required dependencies alphabetically, followed by another blank line and the optional dependencies (those with optional = true) in alphabetical order. Preserve inline comments with their dependency.
Add "python" to every extension-module feature list that builds a Python artefact, keeping it adjacent to "pyo3/extension-module" so the full Python stack is obvious.
When a manifest groups adapters separately (for example crates/pyo3), keep the # Adapters block immediately below the internal crate list so downstream consumers can scan adapter coverage quickly.
Always include a blank line before [dev-dependencies] and [build-dependencies] sections.
Apply the same layout across related manifests when the feature or dependency sets change to avoid drift between crates.
Use snake_case filenames for bin/ sources (for example bin/ws_data.rs) and reflect those paths in each [[bin]] section.
Keep [[bin]] name entries in kebab-case (for example name = "hyperliquid-ws-data") so the compiled binaries retain their intended CLI names.
Versioning guidance
Use workspace inheritance for shared dependencies (for example serde = { workspace = true }).
Only pin versions directly for crate-specific dependencies that are not part of the workspace.
Group workspace-provided dependencies before crate-only dependencies so the inheritance is easy to audit.
Feature flag conventions
Prefer additive feature flags—enabling a feature must not break existing functionality.
Use descriptive flag names that explain what capability is enabled.
Document every feature in the crate-level documentation so consumers know what they toggle.
Common patterns:
high-precision: switches the value-type backing (64-bit or 128-bit integers) to support domains that require extra precision.
default = []: keep defaults minimal.
python: enables Python bindings.
extension-module: builds a Python extension module (always include python).
ffi: enables C FFI bindings.
stubs: exposes testing stubs.
Module organization
Keep modules focused on a single responsibility.
Use mod.rs as the module root when defining submodules.
Prefer relatively flat hierarchies over deep nesting to keep paths manageable.
Re-export commonly used items from the crate root for convenience.
Code style and conventions
File header requirements
All Rust files must include the standardized copyright header:

// -------------------------------------------------------------------------------------------------
//  Copyright (C) 2015-2025 Nautech Systems Pty Ltd. All rights reserved.
//  https://nautechsystems.io
//
//  Licensed under the GNU Lesser General Public License Version 3.0 (the "License");
//  You may not use this file except in compliance with the License.
//  You may obtain a copy of the License at https://www.gnu.org/licenses/lgpl-3.0.en.html
//
//  Unless required by applicable law or agreed to in writing, software
//  distributed under the License is distributed on an "AS IS" BASIS,
//  WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
//  See the License for the specific language governing permissions and
//  limitations under the License.
// -------------------------------------------------------------------------------------------------

Code formatting
Import formatting is automatically handled by rustfmt when running make format. The tool organizes imports into groups (standard library, external crates, local imports) and sorts them alphabetically within each group.

Within this section, follow these spacing rules:

Leave one blank line between functions (including tests) – this improves readability and mirrors the default behavior of rustfmt.
Leave one blank line above every doc comment (/// or //!) so that the comment is clearly detached from the previous code block.
String formatting
Prefer inline format strings over positional arguments:

// Preferred - inline format with variable names
anyhow::bail!("Failed to subtract {n} months from {datetime}");

// Instead of - positional arguments
anyhow::bail!("Failed to subtract {} months from {}", n, datetime);

This makes messages more readable and self-documenting, especially when there are multiple variables.

Type qualification
Follow these conventions for qualifying types in code:

anyhow: Always fully qualify anyhow macros (anyhow::bail!, anyhow::anyhow!) and the Result type (anyhow::Result<T>).
Nautilus domain types: Do not fully qualify Nautilus domain types. Use them directly after importing (e.g., Symbol, InstrumentId, Price).
tokio: Generally fully qualify tokio types as they can have equivalents in std library and other crates (e.g., tokio::spawn, tokio::time::timeout).
use nautilus_model::identifiers::Symbol;

pub fn process_symbol(symbol: Symbol) -> anyhow::Result<()> {
    if !symbol.is_valid() {
        anyhow::bail!("Invalid symbol: {symbol}");
    }

    tokio::spawn(async move {
        // Process symbol asynchronously
    });

    Ok(())
}

Logging
Fully qualify logging macros so the backend is explicit:
Use log::… (log::info!, log::warn!, etc.) inside synchronous core crates.
Use tracing::… (tracing::debug!, tracing::info!, etc.) for async runtimes, adapters, and peripheral components.
Start messages with a capitalised word, prefer complete sentences, and omit terminal periods (e.g. "Processing batch", not "Processing batch.").
Error handling
Use structured error handling patterns consistently:

Primary Pattern: Use anyhow::Result<T> for fallible functions:

pub fn calculate_balance(&mut self) -> anyhow::Result<Money> {
    // Implementation
}

Custom Error Types: Use thiserror for domain-specific errors:

#[derive(Error, Debug)]
pub enum NetworkError {
    #[error("Connection failed: {0}")]
    ConnectionFailed(String),
    #[error("Timeout occurred")]
    Timeout,
}

Error Propagation: Use the ? operator for clean error propagation.

Error Creation: Prefer anyhow::bail! for early returns with errors:

// Preferred - using bail! for early returns
pub fn process_value(value: i32) -> anyhow::Result<i32> {
    if value < 0 {
        anyhow::bail!("Value cannot be negative: {value}");
    }
    Ok(value * 2)
}

// Instead of - verbose return statement
if value < 0 {
    return Err(anyhow::anyhow!("Value cannot be negative: {value}"));
}

Note: Use anyhow::bail! for early returns, but anyhow::anyhow! in closure contexts like ok_or_else() where early returns aren't possible.

Async patterns
Use consistent async/await patterns:

Async function naming: No special suffix is required; prefer natural names.
Tokio usage: Use tokio::spawn for fire-and-forget work, and document when that background task is expected to finish.
Error handling: Return anyhow::Result from async functions to match the synchronous conventions.
Cancellation safety: Call out whether the function is cancellation-safe and what invariants still hold when it is cancelled.
Stream handling: Use tokio_stream (or futures::Stream) for async iterators to make back-pressure explicit.
Timeout patterns: Wrap network or long-running awaits with timeouts (tokio::time::timeout) and propagate or handle the timeout error.
Attribute patterns
Consistent attribute usage and ordering:

#[repr(C)]
#[derive(Clone, Copy, Debug, Hash, PartialEq, Eq, PartialOrd, Ord)]
#[cfg_attr(
    feature = "python",
    pyo3::pyclass(module = "nautilus_trader.model")
)]
pub struct Symbol(Ustr);

For enums with extensive derive attributes:

#[repr(C)]
#[derive(
    Copy,
    Clone,
    Debug,
    Display,
    Hash,
    PartialEq,
    Eq,
    PartialOrd,
    Ord,
    AsRefStr,
    FromRepr,
    EnumIter,
    EnumString,
)]
#[strum(ascii_case_insensitive)]
#[strum(serialize_all = "SCREAMING_SNAKE_CASE")]
#[cfg_attr(
    feature = "python",
    pyo3::pyclass(eq, eq_int, module = "nautilus_trader.model")
)]
pub enum AccountType {
    /// An account with unleveraged cash assets only.
    Cash = 1,
    /// An account which facilitates trading on margin, using account assets as collateral.
    Margin = 2,
}

Constructor patterns
Use the new() vs new_checked() convention consistently:

/// Creates a new [`Symbol`] instance with correctness checking.
///
/// # Errors
///
/// Returns an error if `value` is not a valid string.
///
/// # Notes
///
/// PyO3 requires a `Result` type for proper error handling and stacktrace printing in Python.
pub fn new_checked<T: AsRef<str>>(value: T) -> anyhow::Result<Self> {
    // Implementation
}

/// Creates a new [`Symbol`] instance.
///
/// # Panics
///
/// Panics if `value` is not a valid string.
pub fn new<T: AsRef<str>>(value: T) -> Self {
    Self::new_checked(value).expect(FAILED)
}

Always use the FAILED constant for .expect() messages related to correctness checks:

use nautilus_core::correctness::FAILED;

Constants and naming conventions
Use SCREAMING_SNAKE_CASE for constants with descriptive names:

/// Number of nanoseconds in one second.
pub const NANOSECONDS_IN_SECOND: u64 = 1_000_000_000;

/// Bar specification for 1-minute last price bars.
pub const BAR_SPEC_1_MINUTE_LAST: BarSpecification = BarSpecification {
    step: NonZero::new(1).unwrap(),
    aggregation: BarAggregation::Minute,
    price_type: PriceType::Last,
};

Hash collections
Prefer AHashMap and AHashSet from the ahash crate over the standard library's HashMap and HashSet:

use ahash::{AHashMap, AHashSet};

// Preferred - using AHashMap/AHashSet
let mut symbols: AHashSet<Symbol> = AHashSet::new();
let mut prices: AHashMap<InstrumentId, Price> = AHashMap::new();

// Instead of - standard library HashMap/HashSet
use std::collections::{HashMap, HashSet};
let mut symbols: HashSet<Symbol> = HashSet::new();
let mut prices: HashMap<InstrumentId, Price> = HashMap::new();

Why use ahash?

Superior performance: AHash uses AES-NI hardware instructions when available, providing 2-3x faster hashing compared to the default SipHash.
Low collision rates: Despite being non-cryptographic, AHash provides excellent distribution and low collision rates for typical data.
Drop-in replacement: Fully compatible API with standard library collections.
When to use standard HashMap/HashSet:

Cryptographic security required: Use standard HashMap when hash flooding attacks are a concern (e.g., handling untrusted user input in network protocols).
Network clients: Currently prefer standard HashMap for network-facing components where security considerations outweigh performance benefits.
Re-export patterns
Organize re-exports alphabetically and place at the end of lib.rs files:

// Re-exports
pub use crate::{
    nanos::UnixNanos,
    time::AtomicTime,
    uuid::UUID4,
};

// Module-level re-exports
pub use crate::identifiers::{
    account_id::AccountId,
    actor_id::ActorId,
    client_id::ClientId,
};

Documentation standards
Module-Level documentation
All modules must have module-level documentation starting with a brief description:

//! Functions for correctness checks similar to the *design by contract* philosophy.
//!
//! This module provides validation checking of function or method conditions.
//!
//! A condition is a predicate which must be true just prior to the execution of
//! some section of code - for correct behavior as per the design specification.

For modules with feature flags, document them clearly:

//! # Feature flags
//!
//! This crate provides feature flags to control source code inclusion during compilation,
//! depending on the intended use case:
//!
//! - `ffi`: Enables the C foreign function interface (FFI) from [cbindgen](https://github.com/mozilla/cbindgen).
//! - `python`: Enables Python bindings from [PyO3](https://pyo3.rs).
//! - `extension-module`: Builds as a Python extension module (used with `python`).
//! - `stubs`: Enables type stubs for use in testing scenarios.


Field documentation
All struct and enum fields must have documentation with terminating periods:

pub struct Currency {
    /// The currency code as an alpha-3 string (e.g., "USD", "EUR").
    pub code: Ustr,
    /// The currency decimal precision.
    pub precision: u8,
    /// The ISO 4217 currency code.
    pub iso4217: u16,
    /// The full name of the currency.
    pub name: Ustr,
    /// The currency type, indicating its category (e.g. Fiat, Crypto).
    pub currency_type: CurrencyType,
}

Function documentation
Document all public functions with:

Purpose and behavior
Explanation of input argument usage
Error conditions (if applicable)
Panic conditions (if applicable)
/// Returns a reference to the `AccountBalance` for the specified currency, or `None` if absent.
///
/// # Panics
///
/// Panics if `currency` is `None` and `self.base_currency` is `None`.
pub fn base_balance(&self, currency: Option<Currency>) -> Option<&AccountBalance> {
    // Implementation
}

Errors and panics documentation format
For single line errors and panics documentation, use sentence case with the following convention:

/// Returns a reference to the `AccountBalance` for the specified currency, or `None` if absent.
///
/// # Errors
///
/// Returns an error if the currency conversion fails.
///
/// # Panics
///
/// Panics if `currency` is `None` and `self.base_currency` is `None`.
pub fn base_balance(&self, currency: Option<Currency>) -> anyhow::Result<Option<&AccountBalance>> {
    // Implementation
}

For multi-line errors and panics documentation, use sentence case with bullets and terminating periods:

/// Calculates the unrealized profit and loss for the position.
///
/// # Errors
///
/// Returns an error if:
/// - The market price for the instrument cannot be found.
/// - The conversion rate calculation fails.
/// - Invalid position state is encountered.
///
/// # Panics
///
/// This function panics if:
/// - The instrument ID is invalid or uninitialized.
/// - Required market data is missing from the cache.
/// - Internal state consistency checks fail.
pub fn calculate_unrealized_pnl(&self, market_price: Price) -> anyhow::Result<Money> {
    // Implementation
}

Safety documentation format
For Safety documentation, use the SAFETY: prefix followed by a short description explaining why the unsafe operation is valid:

/// Creates a new instance from raw components without validation.
///
/// # Safety
///
/// The caller must ensure that all input parameters are valid and properly initialized.
pub unsafe fn from_raw_parts(ptr: *const u8, len: usize) -> Self {
    // SAFETY: Caller guarantees ptr is valid and len is correct
    Self {
        data: std::slice::from_raw_parts(ptr, len),
    }
}

For inline unsafe blocks, use the SAFETY: comment directly above the unsafe code:

impl Send for MessageBus {
    fn send(&self) {
        // SAFETY: Message bus is not meant to be passed between threads
        unsafe {
            // unsafe operation here
        }
    }
}

Python bindings
Python bindings are provided via Cython and PyO3, allowing users to import NautilusTrader crates directly in Python without a Rust toolchain.

PyO3 naming conventions
When exposing Rust functions to Python via PyO3:

The Rust symbol must be prefixed with py_* to make its purpose explicit inside the Rust codebase.
Use the #[pyo3(name = "…")] attribute to publish the Python name without the py_ prefix so the Python API remains clean.
#[pyo3(name = "do_something")]
pub fn py_do_something() -> PyResult<()> {
    // …
}

Testing conventions
Use mod tests as the standard test module name unless you need to specifically compartmentalize.
Use #[rstest] attributes consistently, this standardization reduces cognitive overhead.
Do not use Arrange, Act, Assert separator comments in Rust tests.
Test organization
Use consistent test module structure with section separators:

////////////////////////////////////////////////////////////////////////////////
// Tests
////////////////////////////////////////////////////////////////////////////////

#[cfg(test)]
mod tests {
    use rstest::rstest;
    use super::*;
    use crate::identifiers::{Symbol, stubs::*};

    #[rstest]
    fn test_string_reprs(symbol_eth_perp: Symbol) {
        assert_eq!(symbol_eth_perp.as_str(), "ETH-PERP");
        assert_eq!(format!("{symbol_eth_perp}"), "ETH-PERP");
    }
}

Parameterized testing
Use the rstest attribute consistently, and for parameterized tests:

#[rstest]
#[case("AUDUSD", false)]
#[case("AUD/USD", false)]
#[case("CL.FUT", true)]
fn test_symbol_is_composite(#[case] input: &str, #[case] expected: bool) {
    let symbol = Symbol::new(input);
    assert_eq!(symbol.is_composite(), expected);
}

Test naming
Use descriptive test names that explain the scenario:

fn test_sma_with_no_inputs()
fn test_sma_with_single_input()
fn test_symbol_is_composite()

Rust-Python memory management
When working with PyO3 bindings, it's critical to understand and avoid reference cycles between Rust's Arc reference counting and Python's garbage collector. This section documents best practices for handling Python objects in Rust callback-holding structures.

The reference cycle problem
Problem: Using Arc<PyObject> in callback-holding structs creates circular references:

Rust Arc holds Python objects → increases Python reference count.
Python objects might reference Rust objects → creates cycles.
Neither side can be garbage collected → memory leak.
Example of problematic pattern:

// AVOID: This creates reference cycles
struct CallbackHolder {
    handler: Option<Arc<PyObject>>,  // ❌ Arc wrapper causes cycles
}

The solution: GIL-based cloning
Solution: Use plain PyObject with proper GIL-based cloning via clone_py_object():

use nautilus_core::python::clone_py_object;

// CORRECT: Use plain PyObject without Arc wrapper
struct CallbackHolder {
    handler: Option<PyObject>,  // ✅ No Arc wrapper
}

// Manual Clone implementation using clone_py_object
impl Clone for CallbackHolder {
    fn clone(&self) -> Self {
        Self {
            handler: self.handler.as_ref().map(clone_py_object),
        }
    }
}

Best practices
1. Use clone_py_object() for Python object cloning
// When cloning Python callbacks
let cloned_callback = clone_py_object(&original_callback);

// In manual Clone implementations
self.py_handler.as_ref().map(clone_py_object)

2. Remove #[derive(Clone)] from callback-holding structs
// BEFORE: Automatic derive causes issues with PyObject
#[derive(Clone)]  // ❌ Remove this
struct Config {
    handler: Option<PyObject>,
}

// AFTER: Manual implementation with proper cloning
struct Config {
    handler: Option<PyObject>,
}

impl Clone for Config {
    fn clone(&self) -> Self {
        Self {
            // Clone regular fields normally
            url: self.url.clone(),
            // Use clone_py_object for Python objects
            handler: self.handler.as_ref().map(clone_py_object),
        }
    }
}

3. Update function signatures to accept PyObject
// BEFORE: Arc wrapper in function signatures
fn spawn_task(handler: Arc<PyObject>) { ... }  // ❌

// AFTER: Plain PyObject
fn spawn_task(handler: PyObject) { ... }  // ✅

4. Avoid Arc::new() when creating Python callbacks
// BEFORE: Wrapping in Arc
let callback = Arc::new(py_function);  // ❌

// AFTER: Use directly
let callback = py_function;  // ✅

Why this works
The clone_py_object() function:

Acquires the Python GIL before performing clone operations.
Uses Python's native reference counting via clone_ref().
Avoids Rust Arc wrappers that interfere with Python GC.
Maintains thread safety through proper GIL management.
This approach allows both Rust and Python garbage collectors to work correctly, eliminating memory leaks from reference cycles.

Common anti-patterns
Avoid .clone() in hot paths – favour borrowing or shared ownership via Arc.
Avoid .unwrap() in production code – generally propagate errors with ? or map them into domain errors, but unwrapping lock poisoning is acceptable because it signals a severe program state that should abort fast.
Avoid String when &str suffices – minimise allocations on tight loops.
Avoid exposing interior mutability – hide mutexes/RefCell behind safe APIs.
Avoid large structs in Result<T, E> – box large error payloads (Box<dyn Error + Send + Sync>).
Unsafe Rust
It will be necessary to write unsafe Rust code to be able to achieve the value of interoperating between Cython and Rust. The ability to step outside the boundaries of safe Rust is what makes it possible to implement many of the most fundamental features of the Rust language itself, just as C and C++ are used to implement their own standard libraries.

Great care will be taken with the use of Rusts unsafe facility - which just enables a small set of additional language features, thereby changing the contract between the interface and caller, shifting some responsibility for guaranteeing correctness from the Rust compiler, and onto us. The goal is to realize the advantages of the unsafe facility, whilst avoiding any undefined behavior. The definition for what the Rust language designers consider undefined behavior can be found in the language reference.

Safety policy
To maintain correctness, any use of unsafe Rust must follow our policy:

If a function is unsafe to call, there must be a Safety section in the documentation explaining why the function is unsafe. and covering the invariants which the function expects the callers to uphold, and how to meet their obligations in that contract.
Document why each function is unsafe in its doc comment's Safety section, and cover all unsafe blocks with unit tests.
Always include a SAFETY: comment explaining why the unsafe operation is valid:
// SAFETY: Message bus is not meant to be passed between threads
#[allow(unsafe_code)]

unsafe impl Send for MessageBus {}

Crate-level lint – every crate that exposes FFI symbols enables #![deny(unsafe_op_in_unsafe_fn)]. Even inside an unsafe fn, each pointer dereference or other dangerous operation must be wrapped in its own unsafe { … } block.

CVec contract – for raw vectors that cross the FFI boundary read the FFI Memory Contract. Foreign code becomes the owner of the allocation and must call the matching vec_drop_* function exactly once.

Tooling configuration
The project uses several tools for code quality:

rustfmt: Automatic code formatting (see rustfmt.toml).
clippy: Linting and best practices (see clippy.toml).
cbindgen: C header generation for FFI.
Rust version management
The project pins to a specific Rust version via rust-toolchain.toml.

Keep your toolchain synchronized with CI:

rustup update       # Update to latest stable Rust
rustup show         # Verify correct toolchain is active

If pre-commit passes locally but fails in CI, clear the pre-commit cache and re-run:

pre-commit clean    # Clear cached environments
make pre-commit     # Re-run all checks

This ensures you're using the same Rust and clippy versions as CI.

Resources
The Rustonomicon – The Dark Arts of Unsafe Rust.
The Rust Reference – Unsafety.
Safe Bindings in Rust – Russell Johnston.
Google – Rust and C interoperability.

Rust API
List of all crates

bitmex_http
bitmex_ws_data
bitmex_ws_exec
bybit_http
bybit_ws_data
coinbase_intx_http_private
coinbase_intx_http_public
coinbase_intx_ws
databento_node_test
databento_sandbox
hyperliquid_http_exec
hyperliquid_http_private
hyperliquid_http_public
hyperliquid_ws_data
hyperliquid_ws_exec
hyperliquid_ws_post
nautilus
nautilus_analysis
nautilus_backtest
nautilus_bitmex
nautilus_blockchain
nautilus_bybit
nautilus_cli
nautilus_coinbase_intx
nautilus_common
nautilus_core
nautilus_cryptography
nautilus_data
nautilus_databento
nautilus_execution
nautilus_hyperliquid
nautilus_indicators
nautilus_infrastructure
nautilus_live
nautilus_model
nautilus_network
nautilus_okx
nautilus_persistence
nautilus_portfolio
nautilus_pyo3
nautilus_risk
nautilus_serialization
nautilus_system
nautilus_tardis
nautilus_testkit
nautilus_trader
nautilus_trading
node_test
okx_http_private
okx_http_public
okx_ws_data
okx_ws_exec
python_stub_gen
stream_deltas_bench
tardis_csv
tardis_http
tardis_replay
to_json
to_parquet


Implementation goals
The primary goal of NautilusTrader is to provide a unified trading system for use with a variety of integrations. To support the widest range of trading strategies, priority will be given to standard functionality:

Requesting historical market data.
Streaming live market data.
Reconciling execution state.
Submitting standard order types with standard execution instructions.
Modifying existing orders (if possible on an exchange).
Canceling orders.
The implementation of each integration aims to meet the following criteria:

Low-level client components should match the exchange API as closely as possible.
The full range of an exchange's functionality (where applicable to NautilusTrader) should eventually be supported.
Exchange specific data types will be added to support the functionality and return types which are reasonably expected by a user.
Actions unsupported by an exchange or NautilusTrader will be logged as a warning or error when invoked.
API unification
All integrations must conform to NautilusTrader’s system API, requiring normalization and standardization:

Symbols should use the venue’s native symbol format unless disambiguation is required (e.g., Binance Spot vs. Binance Futures).
Timestamps must use UNIX epoch nanoseconds. If milliseconds are used, field/property names should explicitly end with _ms.

Coding Standards
Code Style
The current codebase can be used as a guide for formatting conventions. Additional guidelines are provided below.

Universal formatting rules
The following applies to all source files (Rust, Python, Cython, shell, etc.):

Use spaces only, never hard tab characters.
Lines should generally stay below 100 characters; wrap thoughtfully when necessary.
Prefer American English spelling (color, serialize, behavior).
Comment conventions
Generally leave one blank line above every comment block or docstring so it is visually separated from code.
Use sentence case – capitalize the first letter, keep the rest lowercase unless proper nouns or acronyms.
Do not use double spaces after periods.
Single-line comments must not end with a period unless the line ends with a URL or inline Markdown link – in those cases leave the punctuation exactly as the link requires.
Multi-line comments should separate sentences with commas (not period-per-line). The final line should end with a period.
Keep comments concise; favor clarity and only explain the non-obvious – less is more.
Avoid emoji symbols in text.
Doc comment / docstring mood
Python docstrings should be written in the imperative mood – e.g. "Return a cached client."
Rust doc comments should be written in the indicative mood – e.g. "Returns a cached client."
These conventions align with the prevailing styles of each language ecosystem and make generated documentation feel natural to end-users.

Terminology and phrasing
Error messages: Avoid using ", got" in error messages. Use more descriptive alternatives like ", was", ", received", or ", found" depending on context.

❌ "Expected string, got {type(value)}"
✅ "Expected string, was {type(value)}"
Spelling: Use "hardcoded" (single word) rather than "hard-coded" or "hard coded" – this is the more modern and accepted spelling.

Formatting
For longer lines of code, and when passing more than a couple of arguments, you should take a new line which aligns at the next logical indent (rather than attempting a hanging 'vanity' alignment off an opening parenthesis). This practice conserves space to the right, ensures important code is more central in view, and is also robust to function/method name changes.

The closing parenthesis should be located on a new line, aligned at the logical indent.

Also ensure multiple hanging parameters or arguments end with a trailing comma:

long_method_with_many_params(
    some_arg1,
    some_arg2,
    some_arg3,  # <-- trailing comma
)

PEP-8
The codebase generally follows the PEP-8 style guide. Even though C typing is taken advantage of in the Cython parts of the codebase, we still aim to be idiomatic of Python where possible. One notable departure is that Python truthiness is not always taken advantage of to check if an argument is None for everything other than collections.

There are two reasons for this;

Cython can generate more efficient C code from is None and is not None, rather than entering the Python runtime to check the PyObject truthiness.

As per the Google Python Style Guide - it’s discouraged to use truthiness to check if an argument is/is not None, when there is a chance an unexpected object could be passed into the function or method which will yield an unexpected truthiness evaluation (which could result in a logical error type bug).

“Always use if foo is None: (or is not None) to check for a None value. E.g., when testing whether a variable or argument that defaults to None was set to some other value. The other value might be a value that’s false in a boolean context!”

There are still areas that aren’t performance-critical where truthiness checks for None (if foo is None: vs if not foo:) will be acceptable for clarity.

note
Use truthiness to check for empty collections (e.g., if not my_list:) rather than comparing explicitly to None or empty.

We welcome all feedback on where the codebase departs from PEP-8 for no apparent reason.

Python style guide
Type hints
All function and method signatures must include comprehensive type annotations:

def __init__(self, config: EMACrossConfig) -> None:
def on_bar(self, bar: Bar) -> None:
def on_save(self) -> dict[str, bytes]:
def on_load(self, state: dict[str, bytes]) -> None:

Generic Types: Use TypeVar for reusable components

T = TypeVar("T")
class ThrottledEnqueuer(Generic[T]):

Docstrings
The NumPy docstring spec is used throughout the codebase. This needs to be adhered to consistently to ensure the docs build correctly.

Test method naming: Descriptive names explaining the scenario:

def test_currency_with_negative_precision_raises_overflow_error(self):
def test_sma_with_no_inputs_returns_zero_count(self):
def test_sma_with_single_input_returns_expected_value(self):

Ruff
ruff is utilized to lint the codebase. Ruff rules can be found in the top-level pyproject.toml, with ignore justifications typically commented.

Commit messages
Here are some guidelines for the style of your commit messages:

Limit subject titles to 60 characters or fewer. Capitalize subject line and do not end with period.

Use 'imperative voice', i.e. the message should describe what the commit will do if applied.

Optional: Use the body to explain change. Separate from subject with a blank line. Keep under 100 character width. You can use bullet points with or without terminating periods.

Optional: Provide # references to relevant issues or tickets.

Optional: Provide any hyperlinks which are informative.

Gitlint (optional)
Gitlint is available to help enforce commit message standards automatically. It checks that commit messages follow the guidelines above (character limits, formatting, etc.). This is opt-in and not enforced in CI.

Benefits: Encourages concise yet expressive commit messages, helps develop clear explanations of changes.

Installation: First install gitlint to run it locally:

uv pip install gitlint

To enable gitlint as an automatic commit-msg hook:

pre-commit install --hook-type commit-msg

Manual usage: Check your last commit message:

gitlint

Configuration is in .gitlint at the repository root:

60-character title limit: Ensures clear rendering on GitHub and encourages brevity while remaining descriptive.
79-character body width: Aligns with Python's PEP 8 conventions and the traditional limit for git tooling.